
>>> STARTING DATA GENERATION: Mon Aug  8 12:33:32 UTC 2022 (1659962012)

producer1 is starting generation from row number 0
producer2 is starting generation from row number 224000000
producer3 is starting generation from row number 448000000
producer4 is starting generation from row number 672000000
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
initialized 0h:00m:00s:244ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
initialized 0h:00m:00s:258ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
initialized 0h:00m:00s:250ms
Starting data generation proccess...
Loading  <schema> config file

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
initialized 0h:00m:00s:256ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
  finished 1/2 "OS_ORDER"	  in: 0h:01m:01s:931ms size: 6.5 GiB speed: 106.9 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:01m:03s:381ms size: 6.3 GiB speed: 101.1 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:01m:04s:725ms size: 6.5 GiB speed: 102.3 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:01m:05s:550ms size: 6.5 GiB speed: 101.0 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:18s:875ms size: 10.7 GiB speed: 34.2 MiB/s
All work done
Statistics
Overall time	0h:06m:25s:25ms
Generated	17.1 GiB
Speed		45.5 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:04s:215ms
                                                                               
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:28s:517ms size: 10.7 GiB speed: 33.2 MiB/s
All work done
Statistics
Overall time	0h:06m:34s:285ms
Generated	17.1 GiB
Speed		44.5 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:217ms
                                                                               
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:31s:558ms size: 10.5 GiB speed: 32.6 MiB/s
All work done
Statistics
Overall time	0h:06m:35s:363ms
Generated	16.8 GiB
Speed		43.5 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:433ms
                                                                               
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:32s:972ms size: 10.7 GiB speed: 32.8 MiB/s
All work done
Statistics
Overall time	0h:06m:38s:78ms
Generated	17.1 GiB
Speed		44.0 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:378ms

>>> ENDING DATA GENERATION: Mon Aug  8 12:40:11 UTC 2022 (1659962411)


>>> CLEANING PREVIOUS INPUTS/OUTPUTS (HDFS)

rm: `/datasets/query/query-64GB': No such file or directory
rm: `/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: `/outputs/query/join/join-64GB-results': No such file or directory
rm: `/outputs/query/select/select-64GB-results': No such file or directory
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = c29db5f3-b710-47a7-ae9b-23c9c8e2c217

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = cc1da4c7-7015-4eea-830c-142bcc78279f
OK
Time taken: 0.659 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.017 seconds
OK
Time taken: 0.014 seconds

>>> STARTING DATA LOADING (HDFS): Mon Aug  8 12:40:29 UTC 2022 (1659962429)


>>> CREATING HIVE TABLES

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 1ef2fa53-db3c-4a71-8062-4eebccab6380

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 3c1ba705-e168-4832-8df5-05a38993d595
OK
Time taken: 0.964 seconds
OK
Time taken: 0.044 seconds
Query ID = root_20220808124150_37cccb2e-b6f4-403b-8b29-ef5382dd1549
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1658135932618_0064, Tracking URL = http://namenode:8088/proxy/application_1658135932618_0064/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1658135932618_0064
Hadoop job information for Stage-1: number of mappers: 170; number of reducers: 0
2022-08-08 12:42:00,600 Stage-1 map = 0%,  reduce = 0%
2022-08-08 12:42:32,812 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 354.76 sec
2022-08-08 12:42:33,837 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 366.44 sec
2022-08-08 12:42:42,031 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 489.85 sec
2022-08-08 12:42:43,091 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 582.24 sec
2022-08-08 12:42:49,250 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 676.95 sec
2022-08-08 12:42:56,397 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 770.89 sec
2022-08-08 12:42:57,417 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 785.58 sec
2022-08-08 12:42:58,437 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 814.71 sec
2022-08-08 12:43:09,661 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 889.89 sec
2022-08-08 12:43:13,741 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 904.69 sec
2022-08-08 12:43:21,901 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 1119.24 sec
2022-08-08 12:43:34,163 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 1312.86 sec
2022-08-08 12:43:35,188 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 1324.38 sec
2022-08-08 12:43:36,216 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 1329.97 sec
2022-08-08 12:43:37,235 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 1374.6 sec
2022-08-08 12:43:38,253 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 1400.62 sec
2022-08-08 12:43:47,492 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 1566.34 sec
2022-08-08 12:43:49,529 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 1629.75 sec
2022-08-08 12:43:50,552 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 1658.98 sec
2022-08-08 12:43:51,570 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 1682.93 sec
2022-08-08 12:43:52,590 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 1695.2 sec
2022-08-08 12:43:58,710 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 1719.06 sec
2022-08-08 12:44:00,751 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 1735.42 sec
2022-08-08 12:44:25,243 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 2142.1 sec
2022-08-08 12:44:28,302 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 2200.74 sec
2022-08-08 12:44:30,340 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 2213.35 sec
2022-08-08 12:44:31,360 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 2256.53 sec
2022-08-08 12:44:32,380 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 2279.87 sec
2022-08-08 12:44:37,477 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 2372.95 sec
2022-08-08 12:44:39,513 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 2424.61 sec
2022-08-08 12:44:41,551 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 2440.87 sec
2022-08-08 12:44:42,574 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 2459.2 sec
2022-08-08 12:44:43,600 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 2495.63 sec
2022-08-08 12:44:44,619 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 2517.09 sec
2022-08-08 12:44:45,637 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 2533.28 sec
2022-08-08 12:44:46,656 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 2541.04 sec
2022-08-08 12:45:11,110 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 2848.87 sec
2022-08-08 12:45:16,207 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 2945.67 sec
2022-08-08 12:45:19,263 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 3003.16 sec
2022-08-08 12:45:20,282 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 3037.67 sec
2022-08-08 12:45:22,327 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 3063.46 sec
2022-08-08 12:45:23,345 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 3072.1 sec
2022-08-08 12:45:25,427 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 3112.51 sec
2022-08-08 12:45:26,457 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 3129.43 sec
2022-08-08 12:45:28,494 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 3155.39 sec
2022-08-08 12:45:35,627 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 3267.77 sec
2022-08-08 12:45:36,645 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 3280.55 sec
2022-08-08 12:45:37,667 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 3321.35 sec
2022-08-08 12:45:38,692 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 3346.26 sec
2022-08-08 12:45:39,710 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 3382.96 sec
2022-08-08 12:45:45,825 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 3411.2 sec
2022-08-08 12:45:49,907 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 3444.64 sec
2022-08-08 12:45:51,943 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 3491.14 sec
2022-08-08 12:45:52,962 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 3505.95 sec
2022-08-08 12:45:54,999 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 3520.2 sec
2022-08-08 12:45:59,077 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3541.21 sec
MapReduce Total cumulative CPU time: 59 minutes 1 seconds 210 msec
Ended Job = job_1658135932618_0064
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1658135932618_0065, Tracking URL = http://namenode:8088/proxy/application_1658135932618_0065/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1658135932618_0065
Hadoop job information for Stage-3: number of mappers: 11; number of reducers: 0
2022-08-08 12:46:05,526 Stage-3 map = 0%,  reduce = 0%
2022-08-08 12:46:15,771 Stage-3 map = 9%,  reduce = 0%, Cumulative CPU 5.9 sec
2022-08-08 12:46:22,908 Stage-3 map = 31%,  reduce = 0%, Cumulative CPU 146.23 sec
2022-08-08 12:46:29,035 Stage-3 map = 46%,  reduce = 0%, Cumulative CPU 210.26 sec
2022-08-08 12:46:35,145 Stage-3 map = 62%,  reduce = 0%, Cumulative CPU 272.89 sec
2022-08-08 12:46:40,249 Stage-3 map = 64%,  reduce = 0%, Cumulative CPU 279.27 sec
2022-08-08 12:46:41,269 Stage-3 map = 78%,  reduce = 0%, Cumulative CPU 336.01 sec
2022-08-08 12:46:45,348 Stage-3 map = 79%,  reduce = 0%, Cumulative CPU 340.87 sec
2022-08-08 12:46:46,366 Stage-3 map = 84%,  reduce = 0%, Cumulative CPU 358.69 sec
2022-08-08 12:46:47,384 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 394.68 sec
2022-08-08 12:46:48,402 Stage-3 map = 95%,  reduce = 0%, Cumulative CPU 401.56 sec
2022-08-08 12:46:53,500 Stage-3 map = 97%,  reduce = 0%, Cumulative CPU 413.14 sec
2022-08-08 12:46:58,586 Stage-3 map = 99%,  reduce = 0%, Cumulative CPU 424.03 sec
2022-08-08 12:46:59,603 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 425.0 sec
MapReduce Total cumulative CPU time: 7 minutes 5 seconds 0 msec
Ended Job = job_1658135932618_0065
Moving data to directory hdfs://namenode:9000/user/hive/warehouse/item_temp_64gb
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 170   Cumulative CPU: 3541.21 sec   HDFS Read: 45633116701 HDFS Write: 2690488181 SUCCESS
Stage-Stage-3: Map: 11   Cumulative CPU: 425.0 sec   HDFS Read: 2690515249 HDFS Write: 2690473052 SUCCESS
Total MapReduce CPU Time Spent: 0 days 1 hours 6 minutes 6 seconds 210 msec
OK
Time taken: 311.555 seconds

>>> ENDING DATA LOADING (HDFS): Mon Aug  8 12:47:02 UTC 2022 (1659962822)


>>> PRINTING HDFS TREE STRUCTURE FOR GENERATED DATA

HDFS: /datasets/query/query-64GB
 |-----item
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
 |-----order
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt

>>> CLEANING PREVIOUS INPUTS/OUTPUTS (UNICAGE)

rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory

>>> STARTING DATA LOADING (UNICAGE): Mon Aug  8 12:47:06 UTC 2022 (1659962826)


>>> ENDING DATA LOADING (UNICAGE): Mon Aug  8 12:48:14 UTC 2022 (1659962894)


>>> PRINTING UNICAGE TREE STRUCTURE FOR GENERATED DATA

unicageworker1: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker2: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker3: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker4: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker5: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt

>>> CLEANING PRODUCERS LOCALLY


>>> COLLECTING METRICS

