
>>> STARTING DATA GENERATION: Wed Jun 22 11:21:24 UTC 2022 (1655896884)

producer1 is starting generation from row number 0
producer2 is starting generation from row number 448000000
producer3 is starting generation from row number 896000000
producer4 is starting generation from row number 1344000000
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 4480
set XML <property name="SF"> to: 4480.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 4480
set XML <property name="SF"> to: 4480.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '4480.0' and will remain unchanged at this value
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 4480
set XML <property name="SF"> to: 4480.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '4480.0' and will remain unchanged at this value
Loading sucessfull.
All required config files are loaded.
Initializing system...
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 4480
set XML <property name="SF"> to: 4480.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '4480.0' and will remain unchanged at this value
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '4480.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
initialized 0h:00m:00s:244ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 448000000 of 448000000
initialized 0h:00m:00s:253ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 448000000 of 448000000
initialized 0h:00m:00s:242ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 448000000 of 448000000
initialized 0h:00m:00s:250ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 448000000 of 448000000
  finished 1/2 "OS_ORDER"	  in: 0h:02m:02s:230ms size: 12.9 GiB speed: 108.4 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 448000000 of 448000000
  finished 1/2 "OS_ORDER"	  in: 0h:02m:05s:710ms size: 12.7 GiB speed: 103.7 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 448000000 of 448000000
  finished 1/2 "OS_ORDER"	  in: 0h:02m:07s:409ms size: 13.8 GiB speed: 110.7 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 448000000 of 448000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:02m:07s:605ms size: 13.6 GiB speed: 108.9 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 448000000 of 448000000
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:10m:45s:266ms size: 21.3 GiB speed: 33.8 MiB/s
All work done
Overall time	0h:12m:48s:581ms
Generated	34.2 GiB
Speed		45.6 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:01s:82ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:10m:57s:32ms size: 21.6 GiB speed: 33.7 MiB/s
All work done
Overall time	0h:13m:08s:46ms
Generated	35.2 GiB
Speed		45.7 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:03s:406ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:11m:10s:336ms size: 21.7 GiB speed: 33.2 MiB/s
All work done
Statistics
Overall time	0h:13m:18s:68ms
Generated	35.5 GiB
Speed		45.5 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:318ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:11m:19s:310ms size: 21.2 GiB speed: 32.0 MiB/s
All work done
Statistics
Overall time	0h:13m:25s:442ms
Generated	33.9 GiB
Speed		43.1 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:418ms

>>> ENDING DATA GENERATION: Wed Jun 22 11:34:51 UTC 2022 (1655897691)


>>> CLEANING PREVIOUS INPUTS/OUTPUTS (HDFS)

rm: `/datasets/query/query-128GB': No such file or directory
rm: `/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: `/outputs/query/join/join-128GB-results': No such file or directory
rm: `/outputs/query/select/select-128GB-results': No such file or directory
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 5f6bae96-1f45-4883-b9af-b58d2ceb7dd0

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = ca3baaaf-eba5-4f9b-aa97-147c5b68e88f
OK
Time taken: 0.63 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds

>>> STARTING DATA LOADING (HDFS): Wed Jun 22 11:35:09 UTC 2022 (1655897709)


>>> CREATING HIVE TABLES

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 2589cb59-4a08-4c8d-938d-27d21ad47d68

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 6ee4a2de-a913-4e74-b548-6ec6c7df723a
OK
Time taken: 0.934 seconds
OK
Time taken: 0.051 seconds
Query ID = root_20220622113801_83002567-39e4-425b-8fc5-b247b075a407
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1655196875471_0042, Tracking URL = http://namenode:8088/proxy/application_1655196875471_0042/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1655196875471_0042
Hadoop job information for Stage-1: number of mappers: 343; number of reducers: 0
2022-06-22 11:38:09,454 Stage-1 map = 0%,  reduce = 0%
2022-06-22 11:38:42,637 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 365.53 sec
2022-06-22 11:38:51,850 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 566.45 sec
2022-06-22 11:38:52,872 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 583.74 sec
2022-06-22 11:39:05,194 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 775.67 sec
2022-06-22 11:39:06,214 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 797.16 sec
2022-06-22 11:39:23,651 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 894.61 sec
2022-06-22 11:39:31,823 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 1112.78 sec
2022-06-22 11:39:42,030 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 1290.34 sec
2022-06-22 11:39:45,089 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 1354.62 sec
2022-06-22 11:39:46,113 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 1377.24 sec
2022-06-22 11:39:55,300 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 1539.28 sec
2022-06-22 11:39:57,343 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 1614.92 sec
2022-06-22 11:39:58,396 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 1639.55 sec
2022-06-22 11:39:59,427 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 1647.89 sec
2022-06-22 11:40:03,542 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 1670.15 sec
2022-06-22 11:40:11,728 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 1701.78 sec
2022-06-22 11:40:34,194 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 2136.46 sec
2022-06-22 11:40:36,233 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 2172.12 sec
2022-06-22 11:40:37,256 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 2193.86 sec
2022-06-22 11:40:38,275 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 2214.84 sec
2022-06-22 11:40:39,294 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 2240.47 sec
2022-06-22 11:40:46,438 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 2368.2 sec
2022-06-22 11:40:48,477 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 2414.29 sec
2022-06-22 11:40:49,497 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 2441.55 sec
2022-06-22 11:40:50,517 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 2467.01 sec
2022-06-22 11:40:51,548 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 2483.96 sec
2022-06-22 11:41:17,054 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 2801.06 sec
2022-06-22 11:41:26,251 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 2972.16 sec
2022-06-22 11:41:27,271 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 2995.46 sec
2022-06-22 11:41:28,297 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 3007.98 sec
2022-06-22 11:41:29,322 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 3035.72 sec
2022-06-22 11:41:30,341 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 3052.88 sec
2022-06-22 11:41:37,541 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 3159.16 sec
2022-06-22 11:41:40,606 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 3207.51 sec
2022-06-22 11:41:41,630 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 3238.82 sec
2022-06-22 11:41:42,649 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 3254.25 sec
2022-06-22 11:41:43,678 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 3270.17 sec
2022-06-22 11:41:56,955 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 3349.52 sec
2022-06-22 11:42:07,153 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 3601.84 sec
2022-06-22 11:42:18,380 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 3770.84 sec
2022-06-22 11:42:19,400 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 3793.77 sec
2022-06-22 11:42:21,440 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 3823.21 sec
2022-06-22 11:42:22,459 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 3835.96 sec
2022-06-22 11:42:28,577 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 3975.24 sec
2022-06-22 11:42:32,669 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 4062.31 sec
2022-06-22 11:42:33,688 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 4087.29 sec
2022-06-22 11:42:34,706 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 4107.97 sec
2022-06-22 11:42:36,744 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 4126.25 sec
2022-06-22 11:42:45,918 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 4174.52 sec
2022-06-22 11:43:07,393 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 4565.77 sec
2022-06-22 11:43:10,466 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 4613.9 sec
2022-06-22 11:43:12,515 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 4650.64 sec
2022-06-22 11:43:13,535 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 4683.05 sec
2022-06-22 11:43:14,553 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 4700.33 sec
2022-06-22 11:43:16,591 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 4729.17 sec
2022-06-22 11:43:23,726 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 4872.48 sec
2022-06-22 11:43:24,748 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 4904.28 sec
2022-06-22 11:43:25,767 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 4918.48 sec
2022-06-22 11:43:26,797 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 4935.86 sec
2022-06-22 11:43:53,311 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 5278.14 sec
2022-06-22 11:43:57,392 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 5356.74 sec
2022-06-22 11:44:01,485 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 5427.02 sec
2022-06-22 11:44:02,505 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 5460.25 sec
2022-06-22 11:44:03,524 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 5476.46 sec
2022-06-22 11:44:05,563 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 5511.5 sec
2022-06-22 11:44:07,622 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 5538.16 sec
2022-06-22 11:44:14,772 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 5653.5 sec
2022-06-22 11:44:15,790 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 5664.55 sec
2022-06-22 11:44:17,829 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 5696.4 sec
2022-06-22 11:44:18,849 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 5721.28 sec
2022-06-22 11:44:30,090 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 5786.08 sec
2022-06-22 11:44:41,310 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 6042.81 sec
2022-06-22 11:44:48,529 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 6157.74 sec
2022-06-22 11:44:52,606 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 6214.85 sec
2022-06-22 11:44:53,625 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 6229.32 sec
2022-06-22 11:44:56,681 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 6277.64 sec
2022-06-22 11:44:58,719 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 6321.85 sec
2022-06-22 11:45:04,833 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 6461.36 sec
2022-06-22 11:45:06,873 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 6504.49 sec
2022-06-22 11:45:08,911 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 6527.23 sec
2022-06-22 11:45:09,929 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 6548.53 sec
2022-06-22 11:45:20,139 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 6615.06 sec
2022-06-22 11:45:25,227 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 6701.62 sec
2022-06-22 11:45:31,337 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 6820.67 sec
2022-06-22 11:45:37,444 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 6899.32 sec
2022-06-22 11:45:39,479 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 6913.56 sec
2022-06-22 11:45:41,518 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 6934.83 sec
2022-06-22 11:45:53,726 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6987.34 sec
MapReduce Total cumulative CPU time: 0 days 1 hours 56 minutes 27 seconds 340 msec
Ended Job = job_1655196875471_0042
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1655196875471_0043, Tracking URL = http://namenode:8088/proxy/application_1655196875471_0043/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1655196875471_0043
Hadoop job information for Stage-3: number of mappers: 21; number of reducers: 0
2022-06-22 11:46:01,256 Stage-3 map = 0%,  reduce = 0%
2022-06-22 11:46:19,693 Stage-3 map = 2%,  reduce = 0%, Cumulative CPU 46.32 sec
2022-06-22 11:46:20,713 Stage-3 map = 11%,  reduce = 0%, Cumulative CPU 185.97 sec
2022-06-22 11:46:21,731 Stage-3 map = 12%,  reduce = 0%, Cumulative CPU 232.5 sec
2022-06-22 11:46:25,806 Stage-3 map = 15%,  reduce = 0%, Cumulative CPU 255.72 sec
2022-06-22 11:46:26,824 Stage-3 map = 24%,  reduce = 0%, Cumulative CPU 326.37 sec
2022-06-22 11:46:27,845 Stage-3 map = 26%,  reduce = 0%, Cumulative CPU 349.67 sec
2022-06-22 11:46:32,018 Stage-3 map = 29%,  reduce = 0%, Cumulative CPU 372.76 sec
2022-06-22 11:46:33,037 Stage-3 map = 36%,  reduce = 0%, Cumulative CPU 438.42 sec
2022-06-22 11:46:34,056 Stage-3 map = 38%,  reduce = 0%, Cumulative CPU 461.93 sec
2022-06-22 11:46:38,134 Stage-3 map = 41%,  reduce = 0%, Cumulative CPU 484.95 sec
2022-06-22 11:46:39,153 Stage-3 map = 48%,  reduce = 0%, Cumulative CPU 550.0 sec
2022-06-22 11:46:40,170 Stage-3 map = 49%,  reduce = 0%, Cumulative CPU 573.35 sec
2022-06-22 11:46:44,314 Stage-3 map = 52%,  reduce = 0%, Cumulative CPU 602.06 sec
2022-06-22 11:46:45,333 Stage-3 map = 58%,  reduce = 0%, Cumulative CPU 661.57 sec
2022-06-22 11:46:46,351 Stage-3 map = 60%,  reduce = 0%, Cumulative CPU 684.62 sec
2022-06-22 11:46:50,419 Stage-3 map = 64%,  reduce = 0%, Cumulative CPU 724.88 sec
2022-06-22 11:46:51,437 Stage-3 map = 70%,  reduce = 0%, Cumulative CPU 777.07 sec
2022-06-22 11:46:52,455 Stage-3 map = 72%,  reduce = 0%, Cumulative CPU 795.41 sec
2022-06-22 11:46:54,490 Stage-3 map = 73%,  reduce = 0%, Cumulative CPU 798.68 sec
2022-06-22 11:46:56,527 Stage-3 map = 78%,  reduce = 0%, Cumulative CPU 844.09 sec
2022-06-22 11:46:57,549 Stage-3 map = 82%,  reduce = 0%, Cumulative CPU 883.62 sec
2022-06-22 11:46:58,567 Stage-3 map = 84%,  reduce = 0%, Cumulative CPU 902.42 sec
2022-06-22 11:47:00,601 Stage-3 map = 85%,  reduce = 0%, Cumulative CPU 909.73 sec
2022-06-22 11:47:01,617 Stage-3 map = 88%,  reduce = 0%, Cumulative CPU 933.9 sec
2022-06-22 11:47:02,635 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 952.18 sec
2022-06-22 11:47:03,651 Stage-3 map = 92%,  reduce = 0%, Cumulative CPU 969.09 sec
2022-06-22 11:47:04,667 Stage-3 map = 94%,  reduce = 0%, Cumulative CPU 985.58 sec
2022-06-22 11:47:09,750 Stage-3 map = 95%,  reduce = 0%, Cumulative CPU 997.53 sec
2022-06-22 11:47:10,767 Stage-3 map = 97%,  reduce = 0%, Cumulative CPU 1011.5 sec
2022-06-22 11:47:15,851 Stage-3 map = 99%,  reduce = 0%, Cumulative CPU 1028.86 sec
2022-06-22 11:47:16,867 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1035.9 sec
MapReduce Total cumulative CPU time: 17 minutes 15 seconds 900 msec
Ended Job = job_1655196875471_0043
Moving data to directory hdfs://namenode:9000/user/hive/warehouse/item_temp_128gb
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 343   Cumulative CPU: 6987.34 sec   HDFS Read: 92169912779 HDFS Write: 5380103337 SUCCESS
Stage-Stage-3: Map: 21   Cumulative CPU: 1035.9 sec   HDFS Read: 5380156055 HDFS Write: 5380072468 SUCCESS
Total MapReduce CPU Time Spent: 0 days 2 hours 13 minutes 43 seconds 240 msec
OK
Time taken: 558.636 seconds

>>> ENDING DATA LOADING (HDFS): Wed Jun 22 11:47:20 UTC 2022 (1655898440)


>>> PRINTING HDFS TREE STRUCTURE FOR GENERATED DATA

HDFS: /datasets/query/query-128GB
 |-----item
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
 |-----order
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt

>>> CLEANING PREVIOUS INPUTS/OUTPUTS (UNICAGE)

rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-128GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-128GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-128GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-128GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-128GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-128GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-128GB-results': No such file or directory

>>> STARTING DATA LOADING (UNICAGE): Wed Jun 22 11:47:24 UTC 2022 (1655898444)


>>> ENDING DATA LOADING (UNICAGE): Wed Jun 22 11:49:50 UTC 2022 (1655898590)


>>> PRINTING UNICAGE TREE STRUCTURE FOR GENERATED DATA

unicageworker1: ~/datav/datasets/query/query-128GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker2: ~/datav/datasets/query/query-128GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker3: ~/datav/datasets/query/query-128GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker4: ~/datav/datasets/query/query-128GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker5: ~/datav/datasets/query/query-128GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt

>>> CLEANING PRODUCERS LOCALLY


>>> COLLECTING METRICS

