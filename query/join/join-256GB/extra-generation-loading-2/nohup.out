
>>> STARTING DATA GENERATION: Mon Aug  8 14:25:24 UTC 2022 (1659968724)

producer1 is starting generation from row number 0
producer2 is starting generation from row number 896000000
producer3 is starting generation from row number 1792000000
producer4 is starting generation from row number 2688000000
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'GENERATION_PROGRESS_UPDATE_INTERVALL' from 1000 to: 20000
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 8960
set XML <property name="SF"> to: 8960.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 8960
set XML <property name="SF"> to: 8960.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 8960
set XML <property name="SF"> to: 8960.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '8960.0' and will remain unchanged at this value
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 8960
set XML <property name="SF"> to: 8960.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '8960.0' and will remain unchanged at this value
Loading sucessfull.
All required config files are loaded.
Initializing system...
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '8960.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '8960.0' and will remain unchanged at this value
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
initialized 0h:00m:00s:241ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 896000000 of 896000000
initialized 0h:00m:00s:247ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 896000000 of 896000000
initialized 0h:00m:00s:251ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 896000000 of 896000000
initialized 0h:00m:00s:261ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 896000000 of 896000000
  finished 1/2 "OS_ORDER"	  in: 0h:04m:04s:410ms size: 27.3 GiB speed: 114.6 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 896000000 of 896000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:04m:10s:851ms size: 27.5 GiB speed: 112.4 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 896000000 of 896000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:04m:12s:392ms size: 25.7 GiB speed: 104.1 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 896000000 of 896000000
                                                                               
  finished 1/2 "OS_ORDER"	  in: 0h:04m:17s:276ms size: 27.5 GiB speed: 109.6 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 896000000 of 896000000
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:21m:23s:551ms size: 43.3 GiB speed: 34.6 MiB/s
All work done
Statistics
Overall time	0h:25m:30s:4ms
Generated	70.7 GiB
Speed		47.3 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:02s:38ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:21m:56s:999ms size: 43.4 GiB speed: 33.8 MiB/s
All work done
Statistics
Overall time	0h:26m:14s:599ms
Generated	71.0 GiB
Speed		46.2 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:362ms
                                                                               
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:22m:06s:454ms size: 43.4 GiB speed: 33.5 MiB/s
All work done
                                                                               
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:22m:05s:97ms size: 42.5 GiB speed: 32.8 MiB/s
All work done
Statistics
Overall time	0h:26m:20s:983ms
Generated	71.0 GiB
Speed		46.0 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:03s:677ms
Statistics
Overall time	0h:26m:21s:109ms
Generated	68.2 GiB
Speed		44.1 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:03s:618ms

>>> ENDING DATA GENERATION: Mon Aug  8 14:51:47 UTC 2022 (1659970307)


>>> CLEANING PREVIOUS INPUTS/OUTPUTS (HDFS)

rm: `/datasets/query/query-256GB': No such file or directory
rm: `/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: `/outputs/query/join/join-256GB-results': No such file or directory
rm: `/outputs/query/select/select-256GB-results': No such file or directory
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 67454fe1-3c0f-46a0-b6e7-b4c208a16fbd

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 0ab9f3cb-a00b-43c5-b110-ed34cf9a1878
OK
Time taken: 0.639 seconds
OK
Time taken: 0.016 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.013 seconds

>>> STARTING DATA LOADING (HDFS): Mon Aug  8 14:52:05 UTC 2022 (1659970325)


>>> CREATING HIVE TABLES

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = fd9cff52-d561-4ad9-acc4-4339d23d8a26

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 722dcb63-5f36-4736-ae6d-c8c5c871516e
OK
Time taken: 0.958 seconds
OK
Time taken: 0.054 seconds
Query ID = root_20220808145824_62a7ec31-113c-4dad-9932-63f401b57d77
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1658135932618_0068, Tracking URL = http://namenode:8088/proxy/application_1658135932618_0068/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1658135932618_0068
Hadoop job information for Stage-1: number of mappers: 691; number of reducers: 0
2022-08-08 14:58:34,300 Stage-1 map = 0%,  reduce = 0%
2022-08-08 14:59:11,816 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 457.18 sec
2022-08-08 14:59:16,948 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 571.24 sec
2022-08-08 14:59:30,278 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 773.42 sec
2022-08-08 14:59:31,300 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 788.49 sec
2022-08-08 14:59:45,635 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 884.81 sec
2022-08-08 15:00:08,216 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 1312.99 sec
2022-08-08 15:00:10,262 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 1353.23 sec
2022-08-08 15:00:13,342 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 1400.77 sec
2022-08-08 15:00:23,565 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 1640.49 sec
2022-08-08 15:00:24,585 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 1669.35 sec
2022-08-08 15:00:34,801 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 1714.92 sec
2022-08-08 15:01:02,442 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 2193.95 sec
2022-08-08 15:01:04,483 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 2247.99 sec
2022-08-08 15:01:10,609 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 2362.29 sec
2022-08-08 15:01:16,739 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 2495.38 sec
2022-08-08 15:01:17,760 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 2517.65 sec
2022-08-08 15:01:43,301 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 2814.16 sec
2022-08-08 15:01:54,538 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 3025.77 sec
2022-08-08 15:01:56,584 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 3077.62 sec
2022-08-08 15:01:59,646 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 3129.33 sec
2022-08-08 15:02:09,878 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 3298.85 sec
2022-08-08 15:02:11,923 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 3325.16 sec
2022-08-08 15:02:35,397 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 3660.6 sec
2022-08-08 15:02:46,630 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 3837.69 sec
2022-08-08 15:02:50,713 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 3899.2 sec
2022-08-08 15:03:00,912 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 4116.65 sec
2022-08-08 15:03:02,952 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 4164.35 sec
2022-08-08 15:03:06,024 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 4193.34 sec
2022-08-08 15:03:35,672 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 4627.82 sec
2022-08-08 15:03:39,754 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 4699.84 sec
2022-08-08 15:03:43,833 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 4766.32 sec
2022-08-08 15:03:51,998 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 4934.2 sec
2022-08-08 15:03:54,039 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 4981.31 sec
2022-08-08 15:03:57,101 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 5018.5 sec
2022-08-08 15:04:29,818 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 5496.26 sec
2022-08-08 15:04:33,900 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 5582.37 sec
2022-08-08 15:04:37,988 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 5636.95 sec
2022-08-08 15:04:45,140 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 5760.71 sec
2022-08-08 15:04:48,214 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 5787.45 sec
2022-08-08 15:05:04,584 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 5936.24 sec
2022-08-08 15:05:21,994 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 6296.12 sec
2022-08-08 15:05:25,066 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 6361.65 sec
2022-08-08 15:05:34,238 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 6531.84 sec
2022-08-08 15:05:37,319 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 6599.77 sec
2022-08-08 15:05:42,427 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 6666.47 sec
2022-08-08 15:05:52,636 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 6723.09 sec
2022-08-08 15:06:15,096 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 7147.45 sec
2022-08-08 15:06:21,213 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 7261.99 sec
2022-08-08 15:06:25,295 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 7353.66 sec
2022-08-08 15:06:29,373 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 7437.2 sec
2022-08-08 15:06:33,466 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 7480.42 sec
2022-08-08 15:07:02,054 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 7884.85 sec
2022-08-08 15:07:08,173 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 8000.84 sec
2022-08-08 15:07:12,267 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 8081.73 sec
2022-08-08 15:07:18,411 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 8182.99 sec
2022-08-08 15:07:23,541 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 8246.09 sec
2022-08-08 15:07:27,620 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 8290.17 sec
2022-08-08 15:07:51,101 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 8666.69 sec
2022-08-08 15:08:00,292 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 8818.16 sec
2022-08-08 15:08:07,485 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 8942.9 sec
2022-08-08 15:08:11,569 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 9023.09 sec
2022-08-08 15:08:17,689 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 9108.15 sec
2022-08-08 15:08:21,767 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 9156.81 sec
2022-08-08 15:08:47,315 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 9536.84 sec
2022-08-08 15:08:55,486 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 9707.88 sec
2022-08-08 15:08:59,574 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 9784.25 sec
2022-08-08 15:09:03,655 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 9855.39 sec
2022-08-08 15:09:09,780 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 9946.74 sec
2022-08-08 15:09:34,295 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 10277.62 sec
2022-08-08 15:09:40,423 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 10401.29 sec
2022-08-08 15:09:46,549 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 10518.24 sec
2022-08-08 15:09:50,723 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 10599.73 sec
2022-08-08 15:09:56,851 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 10681.39 sec
2022-08-08 15:10:02,977 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 10757.04 sec
2022-08-08 15:10:24,425 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 11073.76 sec
2022-08-08 15:10:29,530 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 11175.54 sec
2022-08-08 15:10:41,789 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 11388.33 sec
2022-08-08 15:10:43,831 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 11419.59 sec
2022-08-08 15:10:53,025 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 11558.17 sec
2022-08-08 15:10:56,085 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 11604.59 sec
2022-08-08 15:11:19,585 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 11930.54 sec
2022-08-08 15:11:29,800 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 12140.54 sec
2022-08-08 15:11:34,905 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 12241.14 sec
2022-08-08 15:11:36,945 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 12286.31 sec
2022-08-08 15:11:44,103 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 12386.98 sec
2022-08-08 15:11:49,206 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 12444.71 sec
2022-08-08 15:12:12,797 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 12809.78 sec
2022-08-08 15:12:19,939 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 12940.81 sec
2022-08-08 15:12:26,074 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 13045.9 sec
2022-08-08 15:12:28,115 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 13084.62 sec
2022-08-08 15:12:40,405 Stage-1 map = 92%,  reduce = 0%, Cumulative CPU 13225.63 sec
2022-08-08 15:12:49,598 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 13348.85 sec
2022-08-08 15:13:03,902 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 13620.11 sec
2022-08-08 15:13:11,061 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 13729.11 sec
2022-08-08 15:13:19,237 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 13864.4 sec
2022-08-08 15:13:22,303 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 13936.82 sec
2022-08-08 15:13:32,548 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 14079.76 sec
2022-08-08 15:13:37,648 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 14151.84 sec
2022-08-08 15:13:59,040 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14271.72 sec
MapReduce Total cumulative CPU time: 0 days 3 hours 57 minutes 51 seconds 720 msec
Ended Job = job_1658135932618_0068
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1658135932618_0069, Tracking URL = http://namenode:8088/proxy/application_1658135932618_0069/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1658135932618_0069
Hadoop job information for Stage-3: number of mappers: 41; number of reducers: 0
2022-08-08 15:14:05,559 Stage-3 map = 0%,  reduce = 0%
2022-08-08 15:14:27,121 Stage-3 map = 1%,  reduce = 0%, Cumulative CPU 46.28 sec
2022-08-08 15:14:33,269 Stage-3 map = 2%,  reduce = 0%, Cumulative CPU 255.58 sec
2022-08-08 15:14:35,313 Stage-3 map = 5%,  reduce = 0%, Cumulative CPU 322.25 sec
2022-08-08 15:14:36,332 Stage-3 map = 6%,  reduce = 0%, Cumulative CPU 348.31 sec
2022-08-08 15:14:37,360 Stage-3 map = 7%,  reduce = 0%, Cumulative CPU 352.06 sec
2022-08-08 15:14:39,399 Stage-3 map = 8%,  reduce = 0%, Cumulative CPU 371.12 sec
2022-08-08 15:14:41,435 Stage-3 map = 12%,  reduce = 0%, Cumulative CPU 443.24 sec
2022-08-08 15:14:42,459 Stage-3 map = 13%,  reduce = 0%, Cumulative CPU 463.57 sec
2022-08-08 15:14:45,524 Stage-3 map = 14%,  reduce = 0%, Cumulative CPU 486.27 sec
2022-08-08 15:14:47,564 Stage-3 map = 18%,  reduce = 0%, Cumulative CPU 563.67 sec
2022-08-08 15:14:49,723 Stage-3 map = 19%,  reduce = 0%, Cumulative CPU 586.01 sec
2022-08-08 15:14:53,804 Stage-3 map = 24%,  reduce = 0%, Cumulative CPU 687.55 sec
2022-08-08 15:14:56,866 Stage-3 map = 25%,  reduce = 0%, Cumulative CPU 716.51 sec
2022-08-08 15:14:59,922 Stage-3 map = 30%,  reduce = 0%, Cumulative CPU 806.06 sec
2022-08-08 15:15:02,974 Stage-3 map = 31%,  reduce = 0%, Cumulative CPU 831.84 sec
2022-08-08 15:15:06,037 Stage-3 map = 35%,  reduce = 0%, Cumulative CPU 920.58 sec
2022-08-08 15:15:07,056 Stage-3 map = 36%,  reduce = 0%, Cumulative CPU 923.48 sec
2022-08-08 15:15:09,091 Stage-3 map = 37%,  reduce = 0%, Cumulative CPU 946.29 sec
2022-08-08 15:15:12,154 Stage-3 map = 42%,  reduce = 0%, Cumulative CPU 1038.05 sec
2022-08-08 15:15:15,206 Stage-3 map = 43%,  reduce = 0%, Cumulative CPU 1061.04 sec
2022-08-08 15:15:17,239 Stage-3 map = 44%,  reduce = 0%, Cumulative CPU 1075.45 sec
2022-08-08 15:15:18,259 Stage-3 map = 48%,  reduce = 0%, Cumulative CPU 1153.03 sec
2022-08-08 15:15:21,327 Stage-3 map = 49%,  reduce = 0%, Cumulative CPU 1175.87 sec
2022-08-08 15:15:23,374 Stage-3 map = 50%,  reduce = 0%, Cumulative CPU 1207.51 sec
2022-08-08 15:15:24,392 Stage-3 map = 53%,  reduce = 0%, Cumulative CPU 1268.05 sec
2022-08-08 15:15:26,431 Stage-3 map = 54%,  reduce = 0%, Cumulative CPU 1283.29 sec
2022-08-08 15:15:29,485 Stage-3 map = 56%,  reduce = 0%, Cumulative CPU 1325.77 sec
2022-08-08 15:15:30,502 Stage-3 map = 59%,  reduce = 0%, Cumulative CPU 1383.35 sec
2022-08-08 15:15:32,611 Stage-3 map = 60%,  reduce = 0%, Cumulative CPU 1398.63 sec
2022-08-08 15:15:34,726 Stage-3 map = 61%,  reduce = 0%, Cumulative CPU 1407.89 sec
2022-08-08 15:15:35,755 Stage-3 map = 65%,  reduce = 0%, Cumulative CPU 1486.21 sec
2022-08-08 15:15:36,774 Stage-3 map = 66%,  reduce = 0%, Cumulative CPU 1509.26 sec
2022-08-08 15:15:41,868 Stage-3 map = 70%,  reduce = 0%, Cumulative CPU 1589.59 sec
2022-08-08 15:15:42,892 Stage-3 map = 71%,  reduce = 0%, Cumulative CPU 1601.53 sec
2022-08-08 15:15:47,988 Stage-3 map = 75%,  reduce = 0%, Cumulative CPU 1688.36 sec
2022-08-08 15:15:49,010 Stage-3 map = 76%,  reduce = 0%, Cumulative CPU 1693.92 sec
2022-08-08 15:15:52,072 Stage-3 map = 77%,  reduce = 0%, Cumulative CPU 1733.17 sec
2022-08-08 15:15:54,107 Stage-3 map = 82%,  reduce = 0%, Cumulative CPU 1819.22 sec
2022-08-08 15:15:57,167 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 1841.18 sec
2022-08-08 15:16:00,226 Stage-3 map = 88%,  reduce = 0%, Cumulative CPU 1930.36 sec
2022-08-08 15:16:03,278 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 1958.42 sec
2022-08-08 15:16:05,319 Stage-3 map = 92%,  reduce = 0%, Cumulative CPU 1999.42 sec
2022-08-08 15:16:06,335 Stage-3 map = 95%,  reduce = 0%, Cumulative CPU 2040.44 sec
2022-08-08 15:16:08,368 Stage-3 map = 96%,  reduce = 0%, Cumulative CPU 2055.29 sec
2022-08-08 15:16:09,386 Stage-3 map = 97%,  reduce = 0%, Cumulative CPU 2066.63 sec
2022-08-08 15:16:14,574 Stage-3 map = 98%,  reduce = 0%, Cumulative CPU 2081.43 sec
2022-08-08 15:16:20,680 Stage-3 map = 99%,  reduce = 0%, Cumulative CPU 2093.35 sec
2022-08-08 15:16:29,831 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2116.77 sec
MapReduce Total cumulative CPU time: 35 minutes 16 seconds 770 msec
Ended Job = job_1658135932618_0069
Moving data to directory hdfs://namenode:9000/user/hive/warehouse/item_temp_256gb
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 691   Cumulative CPU: 14271.72 sec   HDFS Read: 185452466801 HDFS Write: 10757226821 SUCCESS
Stage-Stage-3: Map: 41   Cumulative CPU: 2116.77 sec   HDFS Read: 10757330855 HDFS Write: 10757164632 SUCCESS
Total MapReduce CPU Time Spent: 0 days 4 hours 33 minutes 8 seconds 490 msec
OK
Time taken: 1087.663 seconds

>>> ENDING DATA LOADING (HDFS): Mon Aug  8 15:16:32 UTC 2022 (1659971792)


>>> PRINTING HDFS TREE STRUCTURE FOR GENERATED DATA

HDFS: /datasets/query/query-256GB
 |-----item
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
 |-----order
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt

>>> CLEANING PREVIOUS INPUTS/OUTPUTS (UNICAGE)

rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-256GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-256GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-256GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-256GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-256GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-256GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-256GB-results': No such file or directory

>>> STARTING DATA LOADING (UNICAGE): Mon Aug  8 15:16:36 UTC 2022 (1659971796)


>>> ENDING DATA LOADING (UNICAGE): Mon Aug  8 15:22:19 UTC 2022 (1659972139)


>>> PRINTING UNICAGE TREE STRUCTURE FOR GENERATED DATA

unicageworker1: ~/datav/datasets/query/query-256GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker2: ~/datav/datasets/query/query-256GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker3: ~/datav/datasets/query/query-256GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker4: ~/datav/datasets/query/query-256GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker5: ~/datav/datasets/query/query-256GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt

>>> CLEANING PRODUCERS LOCALLY


>>> COLLECTING METRICS

