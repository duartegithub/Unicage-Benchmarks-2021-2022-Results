
>>> STARTING DATA GENERATION: Wed Jun 22 10:58:17 UTC 2022 (1655895497)

producer1 is starting generation from row number 0
producer2 is starting generation from row number 224000000
producer3 is starting generation from row number 448000000
producer4 is starting generation from row number 672000000
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
Change 'BENCHMARK_OUTPUT_SORTINGCACHE_IO_DISABLED' from false to: false
Change 'SELF_MONITORING_HUMANREADABLE' from false to: false
Change 'SELF_MONITORING_ENABLED' from false to: true
Change 'GENERATION_STATISTICS_TO_FILE' from false to: true
Change 'MEMORY_CHECK_RESTART_PROMT_ENABLED' from true to: true
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
21
23
4
################################################################################
                     PDGF_Demo(single cpu) v3.0_SVNrev88_b4
                       Parallel Data Generation Framework
    by: Frank M., Danisch M., Rabl T. http://www.paralleldatageneration.org
################################################################################
for a command overview start with commandline parameter: -help
or type "help" in the built in shell: PDGF:> 

Set project main scale factor from -notSet- to 2240
set XML <property name="SF"> to: 2240.0

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-schema_cluster.xml
Loading  <schema> config file
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
12: XML <property name="SF">5.0E7 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '2240.0' and will remain unchanged at this value
Loading sucessfull.

Loading cfg file: /root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/config/demo-generation_cluster.xml
Loading  <generation> config file
Loading sucessfull.
All required config files are loaded.
Initializing system...
initialized 0h:00m:00s:258ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
initialized 0h:00m:00s:260ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
initialized 0h:00m:00s:252ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
initialized 0h:00m:00s:266ms
Starting data generation proccess...

generating 1/2 "OS_ORDER"	  rows: 224000000 of 224000000
  finished 1/2 "OS_ORDER"	  in: 0h:01m:01s:683ms size: 6.5 GiB speed: 107.4 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
  finished 1/2 "OS_ORDER"	  in: 0h:01m:03s:162ms size: 6.5 GiB speed: 104.8 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
  finished 1/2 "OS_ORDER"	  in: 0h:01m:04s:539ms size: 6.5 GiB speed: 102.6 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
  finished 1/2 "OS_ORDER"	  in: 0h:01m:05s:253ms size: 6.3 GiB speed: 98.2 MiB/s

generating 2/2 "OS_ORDER_ITEM"	  rows: 224000000 of 224000000
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:13s:967ms size: 10.7 GiB speed: 34.7 MiB/s
All work done
Overall time	0h:06m:21s:146ms
Generated	17.1 GiB
Speed		46.0 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:04s:14ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:19s:723ms size: 10.7 GiB speed: 34.1 MiB/s
All work done
Overall time	0h:06m:22s:413ms
Generated	17.1 GiB
Speed		45.8 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:999ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:35s:909ms size: 10.5 GiB speed: 32.2 MiB/s
All work done
Overall time	0h:06m:42s:654ms
Generated	16.8 GiB
Speed		42.7 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:01s:444ms
  finished 2/2 "OS_ORDER_ITEM"	  in: 0h:05m:51s:945ms size: 10.7 GiB speed: 31.0 MiB/s
All work done
Statistics
Overall time	0h:06m:56s:739ms
Generated	17.1 GiB
Speed		42.1 MiB/s

Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/GenerationStatistics_1.csv
Node 1. logged detailed processing statistics to file:/root/implementation/BigDataGeneratorSuite/Table_datagen/e-com/logs/TableGenerationStatistics_1.csv
Time to stop and flush everything: 0h:00m:00s:254ms

>>> ENDING DATA GENERATION: Wed Jun 22 11:05:16 UTC 2022 (1655895916)


>>> CLEANING PREVIOUS INPUTS/OUTPUTS (HDFS)

rm: `/datasets/query/query-64GB': No such file or directory
rm: `/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: `/outputs/query/join/join-64GB-results': No such file or directory
rm: `/outputs/query/select/select-64GB-results': No such file or directory
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 59a77634-6d43-40ac-9ce4-3f8c2af5fa48

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = c6f7a61e-1584-41f8-83d1-efae8ead381f
OK
Time taken: 0.672 seconds
OK
Time taken: 0.017 seconds
OK
Time taken: 0.016 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.015 seconds
OK
Time taken: 0.014 seconds
OK
Time taken: 0.014 seconds

>>> STARTING DATA LOADING (HDFS): Wed Jun 22 11:05:36 UTC 2022 (1655895936)


>>> CREATING HIVE TABLES

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 35491d62-bd5b-41f8-acd7-a7cf0f08324c

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 0f91c540-3e25-4c5d-aeb4-51137ff0246b
OK
Time taken: 1.02 seconds
OK
Time taken: 0.055 seconds
Query ID = root_20220622110657_53cb2aa7-eee5-4808-9057-b2efa1792f89
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1655196875471_0040, Tracking URL = http://namenode:8088/proxy/application_1655196875471_0040/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1655196875471_0040
Hadoop job information for Stage-1: number of mappers: 170; number of reducers: 0
2022-06-22 11:07:07,642 Stage-1 map = 0%,  reduce = 0%
2022-06-22 11:07:39,700 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 344.85 sec
2022-06-22 11:07:47,878 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 485.81 sec
2022-06-22 11:07:48,904 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 490.98 sec
2022-06-22 11:07:49,968 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 531.32 sec
2022-06-22 11:07:51,004 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 559.83 sec
2022-06-22 11:07:53,058 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 565.13 sec
2022-06-22 11:07:54,087 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 582.69 sec
2022-06-22 11:08:03,352 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 751.13 sec
2022-06-22 11:08:04,372 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 764.78 sec
2022-06-22 11:08:07,448 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 823.26 sec
2022-06-22 11:08:08,483 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 839.64 sec
2022-06-22 11:08:15,652 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 865.63 sec
2022-06-22 11:08:19,741 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 886.37 sec
2022-06-22 11:08:26,882 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 1042.36 sec
2022-06-22 11:08:27,905 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 1081.37 sec
2022-06-22 11:08:40,160 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 1277.79 sec
2022-06-22 11:08:41,184 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 1286.56 sec
2022-06-22 11:08:42,203 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 1306.51 sec
2022-06-22 11:08:43,222 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 1344.93 sec
2022-06-22 11:08:44,245 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 1363.34 sec
2022-06-22 11:08:46,288 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 1406.92 sec
2022-06-22 11:08:47,307 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 1418.67 sec
2022-06-22 11:08:52,421 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 1529.38 sec
2022-06-22 11:08:54,490 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 1566.06 sec
2022-06-22 11:08:55,509 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 1601.03 sec
2022-06-22 11:08:56,528 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 1619.78 sec
2022-06-22 11:08:57,546 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 1626.99 sec
2022-06-22 11:08:58,565 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 1651.18 sec
2022-06-22 11:08:59,584 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 1657.92 sec
2022-06-22 11:09:04,680 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 1687.09 sec
2022-06-22 11:09:05,700 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 1688.85 sec
2022-06-22 11:09:30,199 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 2103.39 sec
2022-06-22 11:09:32,236 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 2135.45 sec
2022-06-22 11:09:34,272 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 2156.64 sec
2022-06-22 11:09:35,292 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 2192.5 sec
2022-06-22 11:09:36,311 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 2217.65 sec
2022-06-22 11:09:37,329 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 2233.61 sec
2022-06-22 11:09:38,352 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 2251.03 sec
2022-06-22 11:09:43,478 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 2352.07 sec
2022-06-22 11:09:44,502 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 2374.75 sec
2022-06-22 11:09:45,521 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 2384.45 sec
2022-06-22 11:09:46,545 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 2401.14 sec
2022-06-22 11:09:47,565 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 2432.55 sec
2022-06-22 11:09:48,632 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 2451.8 sec
2022-06-22 11:09:49,670 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 2460.94 sec
2022-06-22 11:09:50,689 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 2473.15 sec
2022-06-22 11:10:12,098 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 2721.42 sec
2022-06-22 11:10:19,241 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 2871.88 sec
2022-06-22 11:10:22,298 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 2938.01 sec
2022-06-22 11:10:23,328 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 2950.74 sec
2022-06-22 11:10:24,350 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 2966.36 sec
2022-06-22 11:10:25,369 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 2989.06 sec
2022-06-22 11:10:26,388 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 2997.78 sec
2022-06-22 11:10:27,411 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 3024.26 sec
2022-06-22 11:10:28,432 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 3038.6 sec
2022-06-22 11:10:29,451 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 3050.05 sec
2022-06-22 11:10:30,470 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 3061.44 sec
2022-06-22 11:10:31,498 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 3081.55 sec
2022-06-22 11:10:38,643 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 3204.9 sec
2022-06-22 11:10:39,666 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 3245.84 sec
2022-06-22 11:10:40,685 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 3266.14 sec
2022-06-22 11:10:41,710 Stage-1 map = 92%,  reduce = 0%, Cumulative CPU 3278.24 sec
2022-06-22 11:10:42,729 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 3284.35 sec
2022-06-22 11:10:44,766 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 3303.36 sec
2022-06-22 11:10:51,906 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 3338.79 sec
2022-06-22 11:10:54,962 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 3384.21 sec
2022-06-22 11:10:55,980 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 3420.05 sec
2022-06-22 11:10:58,016 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 3434.25 sec
2022-06-22 11:11:01,069 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 3454.9 sec
2022-06-22 11:11:03,107 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3477.61 sec
MapReduce Total cumulative CPU time: 57 minutes 57 seconds 610 msec
Ended Job = job_1655196875471_0040
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1655196875471_0041, Tracking URL = http://namenode:8088/proxy/application_1655196875471_0041/
Kill Command = /usr/local/hadoop//bin/mapred job  -kill job_1655196875471_0041
Hadoop job information for Stage-3: number of mappers: 11; number of reducers: 0
2022-06-22 11:11:11,559 Stage-3 map = 0%,  reduce = 0%
2022-06-22 11:11:23,933 Stage-3 map = 9%,  reduce = 0%, Cumulative CPU 7.33 sec
2022-06-22 11:11:28,019 Stage-3 map = 25%,  reduce = 0%, Cumulative CPU 105.31 sec
2022-06-22 11:11:29,038 Stage-3 map = 31%,  reduce = 0%, Cumulative CPU 145.69 sec
2022-06-22 11:11:34,139 Stage-3 map = 41%,  reduce = 0%, Cumulative CPU 190.16 sec
2022-06-22 11:11:35,159 Stage-3 map = 45%,  reduce = 0%, Cumulative CPU 206.16 sec
2022-06-22 11:11:40,254 Stage-3 map = 56%,  reduce = 0%, Cumulative CPU 250.1 sec
2022-06-22 11:11:41,273 Stage-3 map = 59%,  reduce = 0%, Cumulative CPU 267.16 sec
2022-06-22 11:11:46,375 Stage-3 map = 70%,  reduce = 0%, Cumulative CPU 311.72 sec
2022-06-22 11:11:47,395 Stage-3 map = 73%,  reduce = 0%, Cumulative CPU 327.45 sec
2022-06-22 11:11:50,450 Stage-3 map = 75%,  reduce = 0%, Cumulative CPU 332.6 sec
2022-06-22 11:11:51,473 Stage-3 map = 76%,  reduce = 0%, Cumulative CPU 338.07 sec
2022-06-22 11:11:52,493 Stage-3 map = 84%,  reduce = 0%, Cumulative CPU 369.48 sec
2022-06-22 11:11:53,516 Stage-3 map = 88%,  reduce = 0%, Cumulative CPU 384.55 sec
2022-06-22 11:11:54,535 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 389.56 sec
2022-06-22 11:11:59,623 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 406.13 sec
2022-06-22 11:12:05,726 Stage-3 map = 96%,  reduce = 0%, Cumulative CPU 423.64 sec
2022-06-22 11:12:09,798 Stage-3 map = 97%,  reduce = 0%, Cumulative CPU 427.88 sec
2022-06-22 11:12:10,815 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 438.33 sec
MapReduce Total cumulative CPU time: 7 minutes 18 seconds 330 msec
Ended Job = job_1655196875471_0041
Moving data to directory hdfs://namenode:9000/user/hive/warehouse/item_temp_64gb
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 170   Cumulative CPU: 3477.61 sec   HDFS Read: 45633077567 HDFS Write: 2690488068 SUCCESS
Stage-Stage-3: Map: 11   Cumulative CPU: 438.33 sec   HDFS Read: 2690515339 HDFS Write: 2690472939 SUCCESS
Total MapReduce CPU Time Spent: 0 days 1 hours 5 minutes 15 seconds 940 msec
OK
Time taken: 315.335 seconds

>>> ENDING DATA LOADING (HDFS): Wed Jun 22 11:12:12 UTC 2022 (1655896332)


>>> PRINTING HDFS TREE STRUCTURE FOR GENERATED DATA

HDFS: /datasets/query/query-64GB
 |-----item
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
 |-----order
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt

>>> CLEANING PREVIOUS INPUTS/OUTPUTS (UNICAGE)

rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory
rm: cannot remove '/root/datav/datasets/query/query-64GB': No such file or directory
rm: cannot remove '/root/datav/outputs/query/aggregation/aggregation-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/join/join-64GB-results': No such file or directory
rm: cannot remove '/root/datav/outputs/query/select/select-64GB-results': No such file or directory

>>> STARTING DATA LOADING (UNICAGE): Wed Jun 22 11:12:17 UTC 2022 (1655896337)


>>> ENDING DATA LOADING (UNICAGE): Wed Jun 22 11:13:22 UTC 2022 (1655896402)


>>> PRINTING UNICAGE TREE STRUCTURE FOR GENERATED DATA

unicageworker1: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker2: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker3: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker4: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt
unicageworker5: ~/datav/datasets/query/query-64GB
 |-------OS_ORDER-producer1.txt
 |-------OS_ORDER-producer2.txt
 |-------OS_ORDER-producer3.txt
 |-------OS_ORDER-producer4.txt
 |-------OS_ORDER_ITEM-producer1.txt
 |-------OS_ORDER_ITEM-producer2.txt
 |-------OS_ORDER_ITEM-producer3.txt
 |-------OS_ORDER_ITEM-producer4.txt

>>> CLEANING PRODUCERS LOCALLY


>>> COLLECTING METRICS

